{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting store sales values using Rossmann dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rdm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'Date' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8946787ae2fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#Parsing the Date column into DateTime Object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtypes_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1657\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Usecols do not match names.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1659\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_noconvert_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_set_noconvert_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1724\u001b[0m                         \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1725\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1726\u001b[1;33m                     \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1728\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_set\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1716\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_noconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'Date' is not in list"
     ]
    }
   ],
   "source": [
    "#Reading the variables into a specific data types\n",
    "types_train = {'Sales': np.int32,\n",
    "               'Store': np.int32,\n",
    "               'DayOfWeek': np.int32,\n",
    "               'Date': str,\n",
    "               'Customers': np.int32,\n",
    "               'Open': bool,\n",
    "               'Promo': bool,\n",
    "               'StateHoliday': str,\n",
    "               'SchoolHoliday': bool}\n",
    "\n",
    "#Parsing the Date column into DateTime Object\n",
    "df_train = pd.read_csv('train.csv', dtype=types_train, parse_dates=['Date'])\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Showing the linear relationship between Sales and Customers\n",
    "print(df_train['Customers'].describe())\n",
    "subs_idx = rdm.sample(range(len(df_train)), 8000)\n",
    "df_subset = pd.concat([df_train['Sales'], df_train['Customers']], axis=1).iloc[subs_idx]\n",
    "df_subset.plot.scatter(x='Customers', y='Sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression using single feature (Customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating and fitting data to the model\n",
    "from sklearn import linear_model\n",
    "\n",
    "#Cast to numpy for scikit-learn and only take the non-trivial datapoints\n",
    "ar_data = df_train[df_train['Open'] == True].as_matrix(columns=['Sales', 'Customers'])\n",
    "print(len(ar_data))\n",
    "\n",
    "# Take 20% of randomly chosen datapoints for evaluation\n",
    "n = len(ar_data)\n",
    "np.random.shuffle(ar_data)\n",
    "amnt_eval = int(np.round(0.2*n))\n",
    "print(amnt_eval)\n",
    "train_set = ar_data[amnt_eval:]\n",
    "eval_set = ar_data[:amnt_eval]\n",
    "print(train_set[:, 1])\n",
    "# Train the model\n",
    "linregr = linear_model.LinearRegression()\n",
    "linregr.fit(X=train_set[:, 1].reshape(-1, 1), y=train_set[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicting Sales value and calculating RMSPE \n",
    "eval_y_pred = linregr.predict(eval_set[:, 1].reshape(-1, 1))\n",
    "def rmspe(ar_pred, ar_truth):\n",
    "    \"\"\"\n",
    "    Calculates the root mean square percentage error. Any entries with a truth value of 0 are ignored\n",
    "    \"\"\"\n",
    "    nonzero_idx = np.nonzero(ar_truth)\n",
    "    ar_pred = ar_pred[nonzero_idx]\n",
    "    ar_truth = ar_truth[nonzero_idx]\n",
    "    spe = np.power(np.divide(np.subtract(ar_pred, ar_truth), ar_truth), 2)\n",
    "    return np.sqrt(spe.mean())\n",
    "\n",
    "\n",
    "print(\"RMSPE: {0:0.3f}\".format(rmspe(eval_y_pred, eval_set[:, 0])))\n",
    "\n",
    "accuracy = linregr.score(eval_set[:, 1].reshape(-1, 1),  eval_set[:, 0], sample_weight=None)\n",
    "print (\"Accuracy using Linear Regression is : %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types_store = {'Store': np.int32,\n",
    "               'StoreType': str,\n",
    "               'Assortment': str,\n",
    "               'CompetitionDistance': str, # cant use int here, some cells are empty\n",
    "               'CompetitionOpenSinceMonth': str,\n",
    "               'CompetitionOpenSinceYear': str,\n",
    "               'Promo2': bool,\n",
    "               'Promo2SinceWeek': str,\n",
    "               'Promo2SinceYear': str,\n",
    "               'PromoInterval': str}\n",
    "df_store = pd.read_csv('store.csv',\n",
    "                       dtype=types_store)\n",
    "print('Amount of rows: ' + str(len(df_store)))    \n",
    "print('Missing values? ' + str(df_store.isnull().values.any()))\n",
    "df_store.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Replacing '' values with nan values\n",
    "df_store.replace('', np.nan, inplace=True)\n",
    "df_store.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace missing values at 'CompetitionDistance' with the median of that column.\n",
    "comp_dist_avg = df_store[~df_store['CompetitionDistance'].isnull()]['CompetitionDistance'].astype(np.float32).median()\n",
    "print('Median distance to competitors: ' + str(comp_dist_avg))\n",
    "comp_dist_avg = int(np.round(comp_dist_avg))\n",
    "df_store['CompetitionDistance'].replace(np.nan, str(comp_dist_avg), inplace=True)\n",
    "df_store['CompetitionDistance'] = df_store['CompetitionDistance'].astype(np.int32)\n",
    "df_store.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding meanfull replacements for the columns \"CompetitionOpenSinceMonth/Year' is more difficult. Lets have a closer look at these variables and if they actually influence the sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_comps = df_store[~df_store['CompetitionOpenSinceYear'].isnull()][['Store', 'CompetitionOpenSinceYear']]\n",
    "df_comps = df_comps.astype(np.int32)\n",
    "df_comps.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_comps.groupby(['CompetitionOpenSinceYear']).count().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1900 is an outlier. It probably also doesnt make a difference if a competitor opened 20 or 30 years ago, so we can think about simplifying the data by unifying all pre-2000 datapoints. But lets see the relationship with the sales first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_comps = df_store[~df_store['CompetitionOpenSinceYear'].isnull()]\n",
    "df_comps = df_comps.astype(dtype={'CompetitionOpenSinceYear': np.int32,\n",
    "                       'CompetitionOpenSinceMonth': np.int32})\n",
    "df_merge = pd.merge(df_train[['Store','Sales']], df_comps, how = 'inner', on = 'Store')\n",
    "df_merge = df_merge.groupby('Store').agg(np.mean)\n",
    "df_merge.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aggregated over different dates using the mean, so sales contains the average sale per day for a certain store. The other values are simply the corresponding values for each store. We dont really see any high correlation values here. Suprisingly, Promo2 seems to have a negativ effect on the sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets just replace the missing values with 0 for now, one-hot encode the categorical features and get our complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_store.replace(np.nan, 0, inplace=True)\n",
    "df_store.drop('PromoInterval', axis = 1)\n",
    "df_store = df_store.astype(dtype={'CompetitionOpenSinceYear': np.int32,\n",
    "                       'CompetitionOpenSinceMonth': np.int32})\n",
    "df_merge = pd.merge(df_train, df_comps, how = 'inner', on = 'Store')\n",
    "df_merge['Assortment'] = pd.Categorical(df_merge['Assortment']).codes\n",
    "df_merge['StoreType'] = pd.Categorical(df_merge['StoreType']).codes\n",
    "df_merge = df_merge.drop(labels=['Date'], axis=1)\n",
    "df_merge=df_merge.fillna(value=0)\n",
    "df_merge.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using multiple feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge = df_merge[df_merge['Open'] == True]\n",
    "# Reorder so that the target variable is at first position\n",
    "df_merge.head()\n",
    "cols = list(df_merge.columns.values)\n",
    "cols.remove('Sales')\n",
    "cols.remove('Store')\n",
    "cols.remove('Open')\n",
    "cols.remove('PromoInterval')\n",
    "cols = ['Sales'] + cols\n",
    "df_merge_sub = df_merge[cols]\n",
    "#Cast to numpy for scikit-learn\n",
    "df_merge_sub = df_merge_sub.head(300)\n",
    "ar_data = df_merge_sub.as_matrix()\n",
    "# Take 20% of randomly chosen datapoints for evaluation\n",
    "n = len(ar_data)\n",
    "np.random.shuffle(ar_data)\n",
    "amnt_eval = int(np.round(0.2*n))\n",
    "train_set = ar_data[amnt_eval:]\n",
    "eval_set = ar_data[:amnt_eval]\n",
    "# Train the model\n",
    "linregr = linear_model.LinearRegression()\n",
    "linregr.fit(X=train_set[:, 1:], y=train_set[:, 0])\n",
    "# Make predictions using the testing set\n",
    "eval_y_pred = linregr.predict(eval_set[:, 1:])\n",
    "print(\"RMSPE: %.3f\" % rmspe(eval_y_pred, eval_set[:, 0]))\n",
    "\n",
    "accuracy = linregr.score(eval_set[:, 1:],  eval_set[:, 0], sample_weight=None)\n",
    "print (\"Accuracy using Linear Regression is : %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Model (Bagging Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.svm import SVR\n",
    "#Cast to numpy for scikit-learn\n",
    "ar_data = df_merge_sub.as_matrix()\n",
    "n = len(ar_data)\n",
    "print('Available datapoints: ' + str(n))\n",
    "# Split target variable from rest, apply PCA\n",
    "np.random.shuffle(ar_data)\n",
    "print(ar_data)\n",
    "X=ar_data[:, 1:] \n",
    "y=ar_data[:, 0]\n",
    "# Take 20% of randomly chosen datapoints for evaluation\n",
    "amnt_eval = int(np.round(0.2*n))\n",
    "X_train = X[amnt_eval:]\n",
    "X_eval = X[:amnt_eval]\n",
    "y_train = y[amnt_eval:]\n",
    "y_eval = y[:amnt_eval]\n",
    "# Train the model\n",
    "svr_ensemble = BaggingRegressor(base_estimator=SVR(kernel='linear', C=100, degree=2, epsilon=10, tol=1),\n",
    "                                n_estimators=10,\n",
    "                                max_samples=100,\n",
    "                                max_features=5,\n",
    "                                bootstrap=False,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=100)\n",
    "                                \n",
    "svr_ensemble.fit(X=X_train, y=y_train)\n",
    "# Make predictions using the testing set\n",
    "eval_y_pred = svr_ensemble.predict(X_eval)\n",
    "\n",
    "print(eval_y_pred[0:10])\n",
    "print(y_eval[0:10])\n",
    "print(y[0:10])\n",
    "\n",
    "print(\"RMSPE: %.3f\" % rmspe(eval_y_pred, y_eval))\n",
    "\n",
    "accuracy = svr_ensemble.score(X_eval, y_eval, sample_weight=None)\n",
    "\n",
    "print (\"Accuracy using Bagging Regressor is : %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Regressor with PCA (Principle Component Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.svm import SVR\n",
    "#Cast to numpy for scikit-learn\n",
    "ar_data = df_merge_sub.as_matrix()\n",
    "n = len(ar_data)\n",
    "print('Available datapoints: ' + str(n))\n",
    "# Split target variable from rest, apply PCA\n",
    "np.random.shuffle(ar_data)\n",
    "print(ar_data)\n",
    "X=ar_data[:, 1:] \n",
    "y=ar_data[:, 0]\n",
    "pca = decomposition.PCA(n_components=5)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X)\n",
    "# Take 20% of randomly chosen datapoints for evaluation\n",
    "amnt_eval = int(np.round(0.2*n))\n",
    "X_train = X[amnt_eval:]\n",
    "X_eval = X[:amnt_eval]\n",
    "y_train = y[amnt_eval:]\n",
    "y_eval = y[:amnt_eval]\n",
    "# Train the model\n",
    "svr_ensemble = BaggingRegressor(base_estimator=SVR(kernel='linear', C=100, degree=2, epsilon=10, tol=1),\n",
    "                                n_estimators=10,\n",
    "                                max_samples=100,\n",
    "                                max_features=5,\n",
    "                                bootstrap=False,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=100)\n",
    "                                \n",
    "svr_ensemble.fit(X=X_train, y=y_train)\n",
    "# Make predictions using the testing set\n",
    "eval_y_pred = svr_ensemble.predict(X_eval)\n",
    "\n",
    "print(eval_y_pred[0:10])\n",
    "print(y_eval[0:10])\n",
    "print(y[0:10])\n",
    "\n",
    "print(\"RMSPE: %.3f\" % rmspe(eval_y_pred, y_eval))\n",
    "\n",
    "accuracy = svr_ensemble.score(X_eval, y_eval, sample_weight=None)\n",
    "\n",
    "print (\"Accuracy using Bagging Regressor is : %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "X=ar_data[:, 1:] \n",
    "y=ar_data[:, 0]\n",
    "# Take 20% of randomly chosen datapoints for evaluation\n",
    "amnt_eval = int(np.round(0.2*n))\n",
    "X_train = X[amnt_eval:]\n",
    "X_eval = X[:amnt_eval]\n",
    "y_train = y[amnt_eval:]\n",
    "y_eval = y[:amnt_eval]\n",
    "# Train the model\n",
    "forest = RandomForestRegressor(n_estimators=27, n_jobs=-1)\n",
    "                                \n",
    "forest.fit(X=X_train, y=y_train)\n",
    "# Make predictions using the testing set\n",
    "eval_y_pred = forest.predict(X_eval)\n",
    "\n",
    "print(\"RMSPE: %.3f\" % rmspe(eval_y_pred, y_eval))\n",
    "\n",
    "accuracy = forest.score(X_eval, y_eval, sample_weight=None)\n",
    "print (\"Accuracy using Random Forest Classifier is : %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tbody>\n",
    "<tr>\n",
    "    <td><B>Model</B></td>\n",
    "    <td><B>RMSPE</B></td>\n",
    "    <td><B>Accuracy</B></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Linear Regression with a single feature</td>\n",
    "<td>0.285</td>\n",
    "<td>67.68%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Linear Regression with multiple features</td>\n",
    "<td>0.070</td>\n",
    "<td>87.58%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Bagging Regressor</td>\n",
    "<td>0.128</td>\n",
    "<td>53.24%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Bagging Regressor with PCA&nbsp;</td>\n",
    "<td>0.052</td>\n",
    "<td>95.75%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Random forest classifier</td>\n",
    "<td>0.068</td>\n",
    "<td>91.24%</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>References</h2>\n",
    "<ul>\n",
    "    <p>Notebooks references</p>\n",
    "    <li>https://github.com/SuyashLakhotia/RossmannStoreSales</li>\n",
    "    <li>https://github.com/cutd/Rossmann-Store-Sales</li>\n",
    "    \n",
    "    <p>Bagging Regressor</p>\n",
    "    <li>https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/</li>\n",
    "    <li>http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The code in the document by Kandarp and Naman is licensed under the MIT License https://opensource.org/licenses/MIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
